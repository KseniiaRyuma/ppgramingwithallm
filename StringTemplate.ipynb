{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a String Template\n",
    "\n",
    "\n",
    "#### Setup\n",
    "Set the MakerSuite API key with the provided helper function.\n",
    "\n",
    "import os\n",
    "from utils import get_api_key\n",
    "import google.generativeai as palm\n",
    "from google.api_core import client_options as client_options_lib\n",
    "\n",
    "palm.configure(\n",
    "    api_key=get_api_key(),\n",
    "    transport=\"rest\",\n",
    "    client_options=client_options_lib.ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "#### Pick the model that generates text\n",
    "\n",
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model_bison = models[0]\n",
    "model_bison\n",
    "\n",
    "#### Helper function to call the PaLM API\n",
    "\n",
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text(prompt, \n",
    "                  model=model_bison, \n",
    "                  temperature=0.0):\n",
    "    return palm.generate_text(prompt=prompt,\n",
    "                              model=model,\n",
    "                              temperature=temperature)\n",
    "\n",
    "#### Prompt template\n",
    "\n",
    "1. priming: getting the LLM ready for the type of task you'll ask it to do.\n",
    "2. question: the specific task.\n",
    "3. decorator: how to provide or format the output.\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "{priming}\n",
    "\n",
    "{question}\n",
    "\n",
    "{decorator}\n",
    "\n",
    "Your solution:\n",
    "\"\"\"\n",
    "\n",
    "priming_text = \"You are an expert at writing clear, concise, Python code.\"\n",
    "\n",
    "question = \"create a doubly linked list\"\n",
    "\n",
    "#### Observe how the decorator affects the output\n",
    "- In other non-coding prompt engineering tasks, it's common to use \"chain-of-thought prompting\" by asking the model to work through the task \"step by step\".\n",
    "- For certain tasks like generating code, you may want to experiment with other wording that would make sense if you were asking a developer the same question.\n",
    "\n",
    "In the code cell below, try out option 1 first, then try out option 2.\n",
    "\n",
    "# option 1\n",
    "# decorator = \"Work through it step by step, and show your work. One step per line.\"\n",
    "\n",
    "# option 2\n",
    "decorator = \"Insert comments for each line of code.\"\n",
    "\n",
    "prompt = prompt_template.format(priming=priming_text,\n",
    "                                question=question,\n",
    "                                decorator=decorator)\n",
    "\n",
    "#### review the prompt\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "#### Call the API to get the completion\n",
    "\n",
    "completion = generate_text(prompt)\n",
    "print(completion.result)\n",
    "\n",
    "#### Try another question\n",
    "\n",
    "question = \"\"\"create a very large list of random numbers in python, \n",
    "and then write code to sort that list\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(priming=priming_text,\n",
    "                                question=question,\n",
    "                                decorator=decorator)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "completion = generate_text(prompt)\n",
    "print(completion.result)\n",
    "\n",
    "#### Try out the generated code\n",
    "- Debug it as needed.  For instance, you may need to import `random` in order to use the `random.randint()` function.\n",
    "\n",
    "# copy-paste some of the generated code that generates random numbers\n",
    "random_numbers = [random.randint(0, 100) for _ in range(100000)]\n",
    "print(random_numbers)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
